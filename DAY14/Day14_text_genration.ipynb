{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
   
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aMCfkWj_5OnM"
      },
      "outputs": [],
      "source": [
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397,
          "referenced_widgets": [
            "20f8be58fa4240c99602be8ee78910bf",
            "6182a954ef244afc96f8c4ff0915bb68",
            "781ef1139a87458b8be7f2619e72873d",
            "80cb322b055c4297b531a568227fdd70",
            "b7d7f4fdc44c4480a9e4ffb852f5a177",
            "564aa4d8f41546d6895847f4e670f28e",
            "4ed7b28060f34d61881c9a203e42184e",
            "1c75a0b15eb64a8499129b362e8ae5db",
            "6aae04ff40f54a2fac286d9e376fe487",
            "55774da5370b4dbf82e6e28b08584af7",
            "c447c399d8734330b90b791fc31a337b",
            "b86dbce5fcfd473f90025835f33d6281",
            "77d049256a8742f3b60fe23706577bff",
            "3aae7c01a47b46d692ae2e152c30968b",
            "8eb6d7dcfdc24d1d98a58ea595da038f",
            "1cbc1e2bd3cc407ebfb260f69de42771",
            "6015441d306d43fdad536fd516b562d1",
            "9879904d027f4dbaa0c020a14407a0b4",
            "2c77e0e8f6804a4aadd7460fb930bc71",
            "fde0104510ac46caaf30fe83177b2c1b",
            "212774148a9f4722baea5fc608496b04",
            "7b7f8ca18ee342b594c020d7c7b45cbc",
            "1444ffb4d1f04b7da2d5209035a10c26",
            "a482e35b4d504fd19626a21905885dbe",
            "4d884ef048b244cab0952fd5eea73110",
            "e8aa46cd737c4e65a15856041f4444fc",
            "76a8c64e764544f39163c4713c3dc24b",
            "aa79ebf52ab547009df84b2d1dc6da82",
            "177de791087e4373a35e515338f285f2",
            "8b84315002ec4185ad90333c0d840e65",
            "5d779f0c51f34eabb073ff34ecca104b",
            "9c791c05c4cd4fe999379c7f0e9ad8e8",
            "8a770181d7f14b19a0acda4fab2f4d34",
            "fce4f21ed20f4c05b075abe735316cdf",
            "133705b3973d477abc55f085fb793aab",
            "fff1d76faf4c4470816f5219d62cb6be",
            "8802642827264844911df11c2d44a5d7",
            "fa5e0bacb3d343ed96021d9de244a68c",
            "be55883e1cfd4f02a43841f8da3f9fd6",
            "88b3c5fcaf8e44809b798fccd080b6fa",
            "7144ffee562141bb969508f4ac565930",
            "31c3fc9b8a7d424787806cac75c15abc",
            "c2dfd4bb4119434eb423926ce23b87b4",
            "c83d5eb1ab9f4793b316a81a52505153",
            "9d2bc79cd97c49898842061d957e539b",
            "d23b5c13359e411396f177bcc7e2d32f",
            "b6c1213ea7d74e6d983d932569e7acf0",
            "6341f19efbf946baa74455ace69665a4",
            "1aef56662a0649cdbe748fc2f3e557d8",
            "187f23b97a174e0c9914c096eb0dc087",
            "4a1d590a578c416981c376eb51e0523a",
            "2add0d1b606b4a5896ec3b960ee26098",
            "69e274942eb547c4af00736f09871ddf",
            "cccf6fd87a184a6aad5e157ab58ef835",
            "625ad296b90d408f99eb842696018521",
            "d410e6cfe702495bbd0881535b8032ab",
            "fe6b73707274408da88f2dec7f1443b9",
            "e5a6d876f1eb4c52a6fbc4816dac876c",
            "a0611fb4603a422cb94788382777f338",
            "23f43edeeed547bc9c7216617b98c2f1",
            "e5b1f4a9186149f384925dc29c403978",
            "062ddc17e19e41d89bf3e723c6d78bf3",
            "c0d379e29b13481a820989105d2977d8",
            "83df5950a934431e84518599436dd2f7",
            "f6d155bf7f694509b7629d53f9592f2c",
            "4b4c9ac137f644068636ecf096ff9f9e",
            "e67e3856107d4903b90b9581b9d443bb",
            "9a7b6bc493ea4ed9a728b14dca083d89",
            "f1cc64ca9ec44b70a59a7590b064c9f5",
            "7170a5f094a346a2bf896e857f1e59fd",
            "6ebb668faf884c949a31dbe6142b81d4",
            "9832c6c18971484f93861933665ff0b7",
            "d513ca57a37443cc91b3fe5fcfa41c17",
            "04493e8d5cf548d8987da6dfa9080261",
            "daf54d0486a545b08a955cdb5de2052f",
            "fd3f1adfc52440578f189a77c064d00f",
            "1ab3003ac8db4357bfb8bd2113405e69"
          ]
        },
        "id": "SXGtG-qP8Cox",
        "outputId": "293f36d5-d3ee-443d-f49c-00f2ff1e8dd5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "20f8be58fa4240c99602be8ee78910bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b86dbce5fcfd473f90025835f33d6281"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1444ffb4d1f04b7da2d5209035a10c26"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fce4f21ed20f4c05b075abe735316cdf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d2bc79cd97c49898842061d957e539b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/292 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d410e6cfe702495bbd0881535b8032ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GPT2LMHeadModel LOAD REPORT from: gpt2-medium\n",
            "Key                  | Status     |  | \n",
            "---------------------+------------+--+-\n",
            "h.{0...23}.attn.bias | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e67e3856107d4903b90b9581b9d443bb"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "model_name = \"gpt2-medium\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")"
      ],
      "metadata": {
        "id": "6Vz_AN3gBHdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "model.config.pad_token_id = model.config.eos_token_id\n"
      ],
      "metadata": {
        "id": "4EXzgovDBIX3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_coding_question(prompt):\n",
        "    \"\"\"\n",
        "    Checks if a prompt is related to Python coding using keyword matching.\n",
        "    \"\"\"\n",
        "    coding_keywords = [\"python\", \"code\", \"function\", \"class\", \"import\", \"def \", \"lambda\", \"list\", \"dict\", \"tuple\", \"set\", \"string\", \"int\", \"float\", \"bool\", \"if \", \"else\", \"elif\", \"for \", \"while \", \"try\", \"except\", \"finally\", \"with \", \"as \", \"return\", \"yield\", \"print\", \"input\", \"open\", \"read\", \"write\"]\n",
        "    prompt_lower = prompt.lower()\n",
        "    for keyword in coding_keywords:\n",
        "        if keyword in prompt_lower:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def answer_question(prompt, max_len=100):\n",
        "    \"\"\"\n",
        "    Answers a question if it's related to Python coding, otherwise returns a predefined message.\n",
        "    \"\"\"\n",
        "    if is_coding_question(prompt):\n",
        "        inputs = tokenizer(\n",
        "            prompt,\n",
        "            return_tensors='pt',\n",
        "            padding=True,\n",
        "            return_attention_mask=True\n",
        "        )\n",
        "\n",
        "        # Generate response\n",
        "        output = model.generate(\n",
        "            input_ids=inputs['input_ids'],\n",
        "            attention_mask=inputs['attention_mask'],\n",
        "            max_length=max_len,\n",
        "            num_return_sequences=1,\n",
        "            no_repeat_ngram_size=2,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "        generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "        return generated_text\n",
        "    else:\n",
        "        return \"I can only answer questions related to Python coding.\""
      ],
      "metadata": {
        "id": "4fu7IZe2BRL9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_pairs = []\n",
        "\n",
        "for prompt in [\n",
        "    \"How do you define a function in Python?\",\n",
        "    \"What is a Python list and how is it used?\",\n",
        "    \"What is the difference between a list and a tuple in Python?\",\n",
        "    \"How does a for loop work in Python?\",\n",
        "    \"What is a dictionary in Python and when should you use it?\"\n",
        "]:\n",
        "    qa_pairs.append({\n",
        "        \"prompt\": prompt,\n",
        "        \"response\": answer_question(prompt)\n",
        "    })\n"
      ],
      "metadata": {
        "id": "nJDDPWn7BUAl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for pair in qa_pairs:\n",
        "    print(f\"Prompt: {pair['prompt']}\")\n",
        "    print(f\"Response: {pair['response']}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rrbf3UEDGdkU",
        "outputId": "4a7d4932-bdc6-447d-a262-859bca85cbaf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: How do you define a function in Python?\n",
            "Response: How do you define a function in Python?\n",
            "\n",
            "A function is a method that takes a parameter and returns a value.\n",
            ", , and are functions that take a single parameter, and return a list of values. A function can take multiple parameters, but they must be of the same type. For example, the following function takes two arguments, a string and a number, returns the string, or the number if the first argument is not a valid number. The function returns either a tuple or\n",
            "\n",
            "Prompt: What is a Python list and how is it used?\n",
            "Response: What is a Python list and how is it used?\n",
            "\n",
            "A Python List is an array of items. Each item in the list is associated with a value.\n",
            ", , and are the keys of the Python lists. The values of each item are stored in a dictionary. A dictionary is just a list of keys and values. For example, the following Python code shows how to create a new Python dictionary:\n",
            ". . .\n",
            " .  ( def dictionary ( key : String ,\n",
            "\n",
            "Prompt: What is the difference between a list and a tuple in Python?\n",
            "Response: What is the difference between a list and a tuple in Python?\n",
            "\n",
            "A list is a collection of items. A tuple is an array of tuples.\n",
            ", a Python list, and , a python tuple. The list type is used to represent a sequence of values. It is also used for storing values in a dictionary. For example, the following code shows how to create a new list: >>> from collections import list >>> list = [ 1 , 2 , 3 ] >>> print list [\n",
            "\n",
            "Prompt: How does a for loop work in Python?\n",
            "Response: How does a for loop work in Python?\n",
            "\n",
            "A for-loop is a loop that executes a function. It is used to loop over a collection of items.\n",
            ", , and are the main items in the collection. The for loops are used in many programming languages. In Python, the for statement is the most common way to create a new for in a Python program. For example,\n",
            ".for(i in range(10)) print i\n",
            "The for statements are executed in order\n",
            "\n",
            "Prompt: What is a dictionary in Python and when should you use it?\n",
            "Response: What is a dictionary in Python and when should you use it?\n",
            "\n",
            "A dictionary is an object that contains a list of words. A dictionary can be used to store a set of values, or it can store an array of them.\n",
            ", a Python dictionary, is the most common type of dictionary. It is used for storing a collection of strings. The dictionary has a key and a value. For example, the dictionary \"abc\" contains the string \"ABC\" and the value \"123\n",
            "\n"
          ]
        }
      ]
    }
  ]
}